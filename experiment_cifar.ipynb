{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf73f21-3037-4587-bf31-65d3b29c5322",
   "metadata": {},
   "source": [
    "The code in this notebook replicates the CIFAR-10 vs CIFAR-10.1 experiment of\n",
    "Liu et al.\n",
    "(Learning Deep Kernels for Non-Parametric Two-Sample Tests, \n",
    "ICML 2020). \n",
    "We utilize their code which is under the MIT license:\n",
    "https://github.com/fengliu90/DK-for-TST/blob/master/Deep_Baselines_CIFAR10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb7fb8-022c-4031-bbb2-b3081701ff04",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Environment mmdfuse-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41eb3e-591b-42a1-8b1b-60c517e675be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "Path(\"results\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a16b13-a3a9-457e-be73-1459bb32d9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from all_tests import mmdfuse_test, mmdfuse_ae_test, mmdfuse_ae_new_test\n",
    "from all_tests import mmd_median_test, mmd_split_test\n",
    "from all_tests import mmdagg_test, mmdagginc_test, deep_mmd_test\n",
    "from all_tests import met_test, scf_test\n",
    "from all_tests import ctt_test, actt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c440b-f31b-4c41-afce-40a75363efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "N1 = 1000\n",
    "img_size = 64\n",
    "batch_size = 100\n",
    "K = 10\n",
    "N = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a377f5d-bffa-4649-9c1c-a62693293dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR 10 data and CIFAR 10.1\n",
    "\n",
    "# Configure data loader\n",
    "dataset_test = datasets.CIFAR10(root='./cifar_data/cifar10', download=True,train=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=10000, shuffle=True, num_workers=1)\n",
    "\n",
    "# Obtain CIFAR10 images\n",
    "for i, (imgs, Labels) in enumerate(dataloader_test):\n",
    "    data_all = imgs\n",
    "    label_all = Labels\n",
    "Ind_all = np.arange(len(data_all))\n",
    "\n",
    "# Obtain CIFAR10.1 images\n",
    "data_new = np.load('./cifar_data/cifar10.1_v4_data.npy')\n",
    "data_T = np.transpose(data_new, [0,3,1,2])\n",
    "ind_M = np.random.choice(len(data_T), len(data_T), replace=False)\n",
    "data_T = data_T[ind_M]\n",
    "TT = transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trans = transforms.ToPILImage()\n",
    "data_trans = torch.zeros([len(data_T),3,img_size,img_size])\n",
    "data_T_tensor = torch.from_numpy(data_T)\n",
    "for i in range(len(data_T)):\n",
    "    d0 = trans(data_T_tensor[i])\n",
    "    data_trans[i] = TT(d0)\n",
    "Ind_v4_all = np.arange(len(data_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3029ce2-541c-4d44-84f7-bcb9769c9e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<function mmdfuse_test at 0x7f2bd070e9d0>\n",
      "0.9366197\n",
      " \n",
      "<function mmd_median_test at 0x7f291878a430>\n",
      "0.67800003\n",
      " \n",
      "<function mmd_split_test at 0x7f291878a4c0>\n",
      "0.25100002\n",
      " \n",
      "<function mmdagg_test at 0x7f291878a550>\n",
      "0.883\n",
      " \n",
      "<function mmdagginc_test at 0x7f291878a5e0>\n",
      "0.28077313\n",
      " \n",
      "<function ctt_test at 0x7f291878a820>\n",
      "0.711\n",
      " \n",
      "<function actt_test at 0x7f291878a8b0>\n",
      "0.652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "\n",
    "seed = 0\n",
    "key = random.PRNGKey(42)\n",
    "\n",
    "tests = (mmdfuse_test, mmd_median_test, mmd_split_test, mmdagg_test, mmdagginc_test, ctt_test, actt_test)\n",
    "\n",
    "outputs = [[] for _ in range(len(tests))]\n",
    "for kk in tqdm(range(K)):\n",
    "    torch.manual_seed(kk * 19 + N1)\n",
    "    torch.cuda.manual_seed(kk * 19 + N1)\n",
    "    np.random.seed(seed=1102 * (kk + 10) + N1)\n",
    "\n",
    "    # Collect CIFAR10 images\n",
    "    Ind_tr = np.random.choice(len(data_all), N1, replace=False)\n",
    "    Ind_te = np.delete(Ind_all, Ind_tr)\n",
    "    train_data = []\n",
    "    for i in Ind_tr:\n",
    "        train_data.append([data_all[i], label_all[i]])\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Collect CIFAR10.1 images\n",
    "    np.random.seed(seed=819 * (kk + 9) + N1)\n",
    "    Ind_tr_v4 = np.random.choice(len(data_T), N1, replace=False)\n",
    "    Ind_te_v4 = np.delete(Ind_v4_all, Ind_tr_v4)\n",
    "    New_CIFAR_tr = data_trans[Ind_tr_v4]\n",
    "    New_CIFAR_te = data_trans[Ind_te_v4]\n",
    "    \n",
    "    # Run two-sample test on the training set\n",
    "    # Fetch training data\n",
    "    s1_tr = data_all[Ind_tr]\n",
    "    s2_tr = data_trans[Ind_tr_v4]\n",
    "    \n",
    "    for k in tqdm(range(N)):\n",
    "        # Fetch test data\n",
    "        np.random.seed(seed=1102 * (k + 1) + N1)\n",
    "        data_all_te = data_all[Ind_te]\n",
    "        N_te = len(data_trans) - N1\n",
    "        Ind_N_te = np.random.choice(len(Ind_te), N_te, replace=False)\n",
    "        s1_te = data_all_te[Ind_N_te]\n",
    "        s2_te = data_trans[Ind_te_v4]\n",
    "        \n",
    "        # concatenate the split data\n",
    "        X = jnp.array(torch.concatenate((s1_tr, s1_te)))\n",
    "        Y = jnp.array(torch.concatenate((s2_tr, s2_te)))\n",
    "        \n",
    "        seed += 1\n",
    "        key, subkey = random.split(key)\n",
    "        for t in range(len(tests)):\n",
    "            test = tests[t]\n",
    "            outputs[t].append(test(X, Y, subkey, seed))\n",
    "\n",
    "output = jnp.mean(jnp.array(outputs), -1)\n",
    "\n",
    "if save:\n",
    "    jnp.save(\"results/cifar.npy\", output)\n",
    "\n",
    "for t in range(len(tests)):\n",
    "    print(\" \")\n",
    "    print(tests[t])\n",
    "    print(output[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12db38b-056a-40a5-bff8-2d999099c916",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Environment autogluon-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadd70ba-9f02-4df6-af91-ec32e9155051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "Path(\"results\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee938688-9ed5-4679-93b2-a9a2c1818b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import autotst\n",
    "from utils import HiddenPrints\n",
    "\n",
    "def autotst_test(X, Y, key, seed, time=60):\n",
    "    with HiddenPrints():\n",
    "        tst = autotst.AutoTST(X, Y, split_ratio=0.5, model=autotst.model.AutoGluonTabularPredictor)\n",
    "        tst.split_data()\n",
    "        tst.fit_witness(time_limit=time)  # time limit adjustable to your needs (in seconds)\n",
    "        p_value = tst.p_value_evaluate(permutations=10000)  # control number of permutations in the estimation\n",
    "    return int(p_value <= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f51b8-dde2-4392-ab00-a8306f35692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "N1 = 1000\n",
    "img_size = 64\n",
    "batch_size = 100\n",
    "K = 10\n",
    "N = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d896a9d-b079-439a-a51b-c5ffce6aa95a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR 10 data and CIFAR 10.1\n",
    "\n",
    "# Configure data loader\n",
    "dataset_test = datasets.CIFAR10(root='./cifar_data/cifar10', download=True,train=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=10000, shuffle=True, num_workers=1)\n",
    "\n",
    "# Obtain CIFAR10 images\n",
    "for i, (imgs, Labels) in enumerate(dataloader_test):\n",
    "    data_all = imgs\n",
    "    label_all = Labels\n",
    "Ind_all = np.arange(len(data_all))\n",
    "\n",
    "# Obtain CIFAR10.1 images\n",
    "data_new = np.load('./cifar_data/cifar10.1_v4_data.npy')\n",
    "data_T = np.transpose(data_new, [0,3,1,2])\n",
    "ind_M = np.random.choice(len(data_T), len(data_T), replace=False)\n",
    "data_T = data_T[ind_M]\n",
    "TT = transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trans = transforms.ToPILImage()\n",
    "data_trans = torch.zeros([len(data_T),3,img_size,img_size])\n",
    "data_T_tensor = torch.from_numpy(data_T)\n",
    "for i in range(len(data_T)):\n",
    "    d0 = trans(data_T_tensor[i])\n",
    "    data_trans[i] = TT(d0)\n",
    "Ind_v4_all = np.arange(len(data_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7e673e-0ac4-42ea-b30d-358bf082a519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<function autotst_test at 0x7f4c1cf84af0>\n",
      "0.5438067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "\n",
    "seed = 0\n",
    "key = random.PRNGKey(42)\n",
    "\n",
    "tests = (autotst_test, )\n",
    "\n",
    "outputs = [[] for _ in range(len(tests))]\n",
    "for kk in tqdm(range(K)):\n",
    "    torch.manual_seed(kk * 19 + N1)\n",
    "    torch.cuda.manual_seed(kk * 19 + N1)\n",
    "    np.random.seed(seed=1102 * (kk + 10) + N1)\n",
    "\n",
    "    # Collect CIFAR10 images\n",
    "    Ind_tr = np.random.choice(len(data_all), N1, replace=False)\n",
    "    Ind_te = np.delete(Ind_all, Ind_tr)\n",
    "    train_data = []\n",
    "    for i in Ind_tr:\n",
    "        train_data.append([data_all[i], label_all[i]])\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Collect CIFAR10.1 images\n",
    "    np.random.seed(seed=819 * (kk + 9) + N1)\n",
    "    Ind_tr_v4 = np.random.choice(len(data_T), N1, replace=False)\n",
    "    Ind_te_v4 = np.delete(Ind_v4_all, Ind_tr_v4)\n",
    "    New_CIFAR_tr = data_trans[Ind_tr_v4]\n",
    "    New_CIFAR_te = data_trans[Ind_te_v4]\n",
    "    \n",
    "    # Run two-sample test on the training set\n",
    "    # Fetch training data\n",
    "    s1_tr = data_all[Ind_tr]\n",
    "    s2_tr = data_trans[Ind_tr_v4]\n",
    "    \n",
    "    for k in tqdm(range(N)):\n",
    "        # Fetch test data\n",
    "        np.random.seed(seed=1102 * (k + 1) + N1)\n",
    "        data_all_te = data_all[Ind_te]\n",
    "        N_te = len(data_trans) - N1\n",
    "        Ind_N_te = np.random.choice(len(Ind_te), N_te, replace=False)\n",
    "        s1_te = data_all_te[Ind_N_te]\n",
    "        s2_te = data_trans[Ind_te_v4]\n",
    "        \n",
    "        # MMD-FUSE & MMDAgg do not split the data\n",
    "        s1_tr = jnp.array(s1_tr)\n",
    "        s1_te = jnp.array(s1_te)\n",
    "        s2_tr = jnp.array(s2_tr)\n",
    "        s2_te = jnp.array(s2_te)\n",
    "        \n",
    "        # concatenate the split data\n",
    "        X = jnp.concatenate((s1_tr, s1_te))\n",
    "        Y = jnp.concatenate((s2_tr, s2_te))\n",
    "        \n",
    "        seed += 1\n",
    "        key, subkey = random.split(key)\n",
    "        for t in range(len(tests)):\n",
    "            test = tests[t]\n",
    "            outputs[t].append(client.submit(test, X, Y, subkey, seed))\n",
    "\n",
    "output = jnp.mean(jnp.array(outputs), -1)\n",
    "\n",
    "jnp.save(\"results/cifar_autotst.npy\", output)\n",
    "\n",
    "for t in range(len(tests)):\n",
    "    print(\" \")\n",
    "    print(tests[t])\n",
    "    print(output[t])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
